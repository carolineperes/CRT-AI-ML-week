{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "import sklearn as sk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "Here we setup the data to feed it to the classifier model.\n",
    "\n",
    "The data is located in the folder `../data/EDF_format/`. Each file name and the class it belongs to (Y, output variable) is listed in `../data/eeg_grades.csv`.\n",
    "\n",
    "We want to create columns (lists): file_ID or ID, grade, `fileref`*. The fileref column contains the reference to the EDF file open via `mne.io.read_raw_edf()` from which the manipulations are done. We then slice each file into multiple epochs of fixed length.\n",
    "\n",
    "The input dataframe for the classifier model will have columns: fileID_epochNum | grade (class) | extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing dataset info from eeg_grades.csv: fileID, babyID, num, grade\n",
    "### we want 'fileID' and 'grade'\n",
    "\n",
    "import csv\n",
    "\n",
    "data_info = {}\n",
    "data_classes = {}\n",
    "# get data info from eeg_grades.csv\n",
    "info_filepath = \"../data/eeg_grades.csv\"\n",
    "with open(info_filepath, 'r') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    next(reader)  # skip header line\n",
    "    for row in reader:\n",
    "        data_info[row[0]] = (row[1], row[2], row[3])\n",
    "        data_classes[row[0]] = row[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up data files\n",
    "\n",
    "files_basepath = \"../data/EDF_format/\"\n",
    "files_names_all = list(data_classes.keys())\n",
    "files_names = [name for name, c in data_classes.items() if c != '']\n",
    "data_files = {}\n",
    "for filename in files_names:\n",
    "    file = mne.io.read_raw_edf(files_basepath+filename+\".edf\", preload=True, verbose=False)\n",
    "    data_files[filename] = (file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "# to load data into memory we need to:\n",
    "raw = data_files[files_names[0]].load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDF information\n",
      "Channels: F4,C4,T4,O2,F3,C3,T3,O1,Cz\n",
      "Sampling frequency: 256.0\n",
      "Duration (s): 3600.0\n"
     ]
    }
   ],
   "source": [
    "print(\"EDF information\")\n",
    "channels = raw.ch_names\n",
    "print(\"Channels: \" + ','.join(raw.ch_names))\n",
    "sfreq = raw.info['sfreq']\n",
    "print(\"Sampling frequency: \" + str(raw.info['sfreq']))\n",
    "print(\"Duration (s): \" +  str(float(raw.n_times)/raw.info['sfreq']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set EEG ref as Cz? https://mne.tools/stable/auto_tutorials/preprocessing/55_setting_eeg_reference.html\n",
    "# need to load data to work (preload=True, or raw.load_data)\n",
    "# we also drop Cz as it is now a reference\n",
    "# for raw_id in files_names:\n",
    "    # data_files[raw_id].set_eeg_reference(ref_channels=['Cz'], verbose=False)\n",
    "    # data_files[raw_id] = data_files[raw_id].drop_channels('Cz')\n",
    "\n",
    "channels = data_files[files_names[0]].ch_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each datafile has an EEG recording (duration 1 h or 3600 s) for 8 channels (+ `Cz` as reference).\n",
    "- For each datafile a class (grade from 1 to 4) is given. \n",
    "- If the file does not have a grade, it is part of the prediction set (competition), so we remove it for now, as we are just training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each datafile, separate into epochs.\n",
    "\n",
    "epoch_duration = 30 # in seconds\n",
    "epoch_overlap_t = 0\n",
    "\n",
    "data_epochs = {}\n",
    "\n",
    "for fid, file in data_files.items():\n",
    "    data_epochs[fid] = mne.make_fixed_length_epochs(\n",
    "        file, duration=epoch_duration, overlap=epoch_overlap_t, verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSD - Power Spectral Density\n",
    "\n",
    "The features to be extracted will be the average power spectral density in specific frequency bins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now we build a pandas dataframe in the shape:\n",
    "\n",
    "fileID_epochID (index) | class (y) | PSD_Ch1 (shape = array) | ... | PSD_Ch9 (array)  (9 features of np.array)\n",
    "\n",
    "OR\n",
    "\n",
    "fileID_epochID (index) | class (y) | PSD_Ch1_F1 (shape = float) | PSD_Ch1_F2 | ... | PSD_Ch9_F38 (float)  (38*9 = 342 features)\n",
    "\n",
    "I will try the second method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30s @ 200 Hz\n",
    "epoch_len = 30*200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq bins for aggregation\n",
    "freqs = np.geomspace(0.1, 30.0, num=9)\n",
    "freq_bins = [(freqs[i], freqs[i+1]) for i in range(len(freqs)-1)]\n",
    "freq_bins\n",
    "n_points_fft = 2048 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "\n",
    "for i in range(len(freq_bins)):\n",
    "    for ch_name in channels:\n",
    "        cols.append('PSD_{:s}_f{:d}'.format(ch_name, i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python37\\lib\\site-packages\\ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=(cols+['grade']))\n",
    "\n",
    "fids = [files_names[i] for i in range(3)]\n",
    "\n",
    "for fid, epochs in data_epochs.items():\n",
    "# for fid in fids:\n",
    "    # epochs = data_epochs[fid]\n",
    "    epochs.drop_bad(verbose=False)\n",
    "    n_epochs = len(epochs)\n",
    "    epochs_psds, epochs_psds_freqs = mne.time_frequency.psd_welch(\n",
    "        epochs, fmin=0.1, fmax=30.0, n_fft=n_points_fft, verbose=False)\n",
    "    epochs_psds /= np.sum(epochs_psds, axis=-1, keepdims=True)\n",
    "    X = []\n",
    "    for (fmin,fmax) in freq_bins:\n",
    "        psds_bands = epochs_psds[:, :, (epochs_psds_freqs >= fmin) & (epochs_psds_freqs < fmax)].mean(axis=-1)\n",
    "        X.append(psds_bands.reshape(len(epochs_psds), -1))\n",
    "    X = np.concatenate(X, axis=1)\n",
    "    epochs_features = pd.DataFrame(X, columns=cols, dtype=np.dtype(float))\n",
    "    epochs_features['grade'] = [data_classes[fid]]*n_epochs\n",
    "\n",
    "    df = pd.concat([df, epochs_features], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cols] = df[cols].astype('float')\n",
    "df['grade'] = df['grade'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PSD_F4_f0</th>\n",
       "      <th>PSD_C4_f0</th>\n",
       "      <th>PSD_T4_f0</th>\n",
       "      <th>PSD_O2_f0</th>\n",
       "      <th>PSD_F3_f0</th>\n",
       "      <th>PSD_C3_f0</th>\n",
       "      <th>PSD_T3_f0</th>\n",
       "      <th>PSD_O1_f0</th>\n",
       "      <th>PSD_Cz_f0</th>\n",
       "      <th>PSD_F4_f1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSD_Cz_f6</th>\n",
       "      <th>PSD_F4_f7</th>\n",
       "      <th>PSD_C4_f7</th>\n",
       "      <th>PSD_T4_f7</th>\n",
       "      <th>PSD_O2_f7</th>\n",
       "      <th>PSD_F3_f7</th>\n",
       "      <th>PSD_C3_f7</th>\n",
       "      <th>PSD_T3_f7</th>\n",
       "      <th>PSD_O1_f7</th>\n",
       "      <th>PSD_Cz_f7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12569.000000</td>\n",
       "      <td>12569.000000</td>\n",
       "      <td>12569.000000</td>\n",
       "      <td>12569.000000</td>\n",
       "      <td>12569.000000</td>\n",
       "      <td>12569.000000</td>\n",
       "      <td>12569.000000</td>\n",
       "      <td>12569.000000</td>\n",
       "      <td>12569.000000</td>\n",
       "      <td>12569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.256900e+04</td>\n",
       "      <td>1.256900e+04</td>\n",
       "      <td>1.256900e+04</td>\n",
       "      <td>1.256900e+04</td>\n",
       "      <td>1.256900e+04</td>\n",
       "      <td>1.256900e+04</td>\n",
       "      <td>1.256900e+04</td>\n",
       "      <td>1.256900e+04</td>\n",
       "      <td>1.256900e+04</td>\n",
       "      <td>1.256900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.323152</td>\n",
       "      <td>0.329098</td>\n",
       "      <td>0.316987</td>\n",
       "      <td>0.318852</td>\n",
       "      <td>0.326845</td>\n",
       "      <td>0.336858</td>\n",
       "      <td>0.314173</td>\n",
       "      <td>0.328698</td>\n",
       "      <td>0.326897</td>\n",
       "      <td>0.127266</td>\n",
       "      <td>...</td>\n",
       "      <td>2.196260e-04</td>\n",
       "      <td>2.068503e-04</td>\n",
       "      <td>1.183316e-04</td>\n",
       "      <td>8.826792e-05</td>\n",
       "      <td>1.054856e-04</td>\n",
       "      <td>1.636815e-04</td>\n",
       "      <td>9.549801e-05</td>\n",
       "      <td>1.600020e-04</td>\n",
       "      <td>1.352673e-04</td>\n",
       "      <td>5.970503e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.207294</td>\n",
       "      <td>0.208954</td>\n",
       "      <td>0.208675</td>\n",
       "      <td>0.204949</td>\n",
       "      <td>0.203157</td>\n",
       "      <td>0.208338</td>\n",
       "      <td>0.208243</td>\n",
       "      <td>0.208890</td>\n",
       "      <td>0.207218</td>\n",
       "      <td>0.066548</td>\n",
       "      <td>...</td>\n",
       "      <td>2.914535e-04</td>\n",
       "      <td>4.342999e-04</td>\n",
       "      <td>2.504480e-04</td>\n",
       "      <td>1.987508e-04</td>\n",
       "      <td>3.374096e-04</td>\n",
       "      <td>3.856515e-04</td>\n",
       "      <td>2.133908e-04</td>\n",
       "      <td>4.014707e-04</td>\n",
       "      <td>3.270955e-04</td>\n",
       "      <td>1.401175e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.003615</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>...</td>\n",
       "      <td>1.999945e-07</td>\n",
       "      <td>3.522000e-08</td>\n",
       "      <td>4.288722e-08</td>\n",
       "      <td>4.606564e-08</td>\n",
       "      <td>2.392012e-08</td>\n",
       "      <td>8.628437e-08</td>\n",
       "      <td>3.710131e-08</td>\n",
       "      <td>4.910864e-08</td>\n",
       "      <td>3.721586e-08</td>\n",
       "      <td>2.824243e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.153062</td>\n",
       "      <td>0.160833</td>\n",
       "      <td>0.152843</td>\n",
       "      <td>0.156984</td>\n",
       "      <td>0.162471</td>\n",
       "      <td>0.169128</td>\n",
       "      <td>0.149956</td>\n",
       "      <td>0.163115</td>\n",
       "      <td>0.160610</td>\n",
       "      <td>0.076858</td>\n",
       "      <td>...</td>\n",
       "      <td>5.343705e-05</td>\n",
       "      <td>1.422235e-05</td>\n",
       "      <td>1.135387e-05</td>\n",
       "      <td>1.351561e-05</td>\n",
       "      <td>1.139309e-05</td>\n",
       "      <td>1.409709e-05</td>\n",
       "      <td>1.118693e-05</td>\n",
       "      <td>1.554807e-05</td>\n",
       "      <td>1.188231e-05</td>\n",
       "      <td>8.736179e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.281674</td>\n",
       "      <td>0.284833</td>\n",
       "      <td>0.265713</td>\n",
       "      <td>0.273054</td>\n",
       "      <td>0.289546</td>\n",
       "      <td>0.297018</td>\n",
       "      <td>0.267227</td>\n",
       "      <td>0.287028</td>\n",
       "      <td>0.284308</td>\n",
       "      <td>0.116896</td>\n",
       "      <td>...</td>\n",
       "      <td>1.539860e-04</td>\n",
       "      <td>4.832792e-05</td>\n",
       "      <td>3.004191e-05</td>\n",
       "      <td>3.498999e-05</td>\n",
       "      <td>3.117250e-05</td>\n",
       "      <td>3.580749e-05</td>\n",
       "      <td>3.120121e-05</td>\n",
       "      <td>4.541531e-05</td>\n",
       "      <td>3.682110e-05</td>\n",
       "      <td>2.136704e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.463751</td>\n",
       "      <td>0.468046</td>\n",
       "      <td>0.445826</td>\n",
       "      <td>0.450249</td>\n",
       "      <td>0.463896</td>\n",
       "      <td>0.475233</td>\n",
       "      <td>0.448488</td>\n",
       "      <td>0.461560</td>\n",
       "      <td>0.461103</td>\n",
       "      <td>0.167477</td>\n",
       "      <td>...</td>\n",
       "      <td>2.842402e-04</td>\n",
       "      <td>1.951739e-04</td>\n",
       "      <td>8.691447e-05</td>\n",
       "      <td>7.285828e-05</td>\n",
       "      <td>6.686483e-05</td>\n",
       "      <td>1.074265e-04</td>\n",
       "      <td>7.518804e-05</td>\n",
       "      <td>1.061626e-04</td>\n",
       "      <td>8.855059e-05</td>\n",
       "      <td>4.698250e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.968255</td>\n",
       "      <td>0.968002</td>\n",
       "      <td>0.964592</td>\n",
       "      <td>0.965068</td>\n",
       "      <td>0.974808</td>\n",
       "      <td>0.964966</td>\n",
       "      <td>0.968262</td>\n",
       "      <td>0.971932</td>\n",
       "      <td>0.955733</td>\n",
       "      <td>0.432270</td>\n",
       "      <td>...</td>\n",
       "      <td>6.424147e-03</td>\n",
       "      <td>4.609045e-03</td>\n",
       "      <td>3.868459e-03</td>\n",
       "      <td>2.896981e-03</td>\n",
       "      <td>4.815132e-03</td>\n",
       "      <td>4.759098e-03</td>\n",
       "      <td>2.972491e-03</td>\n",
       "      <td>4.737876e-03</td>\n",
       "      <td>4.155286e-03</td>\n",
       "      <td>2.978245e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PSD_F4_f0     PSD_C4_f0     PSD_T4_f0     PSD_O2_f0     PSD_F3_f0  \\\n",
       "count  12569.000000  12569.000000  12569.000000  12569.000000  12569.000000   \n",
       "mean       0.323152      0.329098      0.316987      0.318852      0.326845   \n",
       "std        0.207294      0.208954      0.208675      0.204949      0.203157   \n",
       "min        0.001486      0.003281      0.001121      0.002183      0.003178   \n",
       "25%        0.153062      0.160833      0.152843      0.156984      0.162471   \n",
       "50%        0.281674      0.284833      0.265713      0.273054      0.289546   \n",
       "75%        0.463751      0.468046      0.445826      0.450249      0.463896   \n",
       "max        0.968255      0.968002      0.964592      0.965068      0.974808   \n",
       "\n",
       "          PSD_C3_f0     PSD_T3_f0     PSD_O1_f0     PSD_Cz_f0     PSD_F4_f1  \\\n",
       "count  12569.000000  12569.000000  12569.000000  12569.000000  12569.000000   \n",
       "mean       0.336858      0.314173      0.328698      0.326897      0.127266   \n",
       "std        0.208338      0.208243      0.208890      0.207218      0.066548   \n",
       "min        0.003615      0.002845      0.001135      0.003115      0.002955   \n",
       "25%        0.169128      0.149956      0.163115      0.160610      0.076858   \n",
       "50%        0.297018      0.267227      0.287028      0.284308      0.116896   \n",
       "75%        0.475233      0.448488      0.461560      0.461103      0.167477   \n",
       "max        0.964966      0.968262      0.971932      0.955733      0.432270   \n",
       "\n",
       "       ...     PSD_Cz_f6     PSD_F4_f7     PSD_C4_f7     PSD_T4_f7  \\\n",
       "count  ...  1.256900e+04  1.256900e+04  1.256900e+04  1.256900e+04   \n",
       "mean   ...  2.196260e-04  2.068503e-04  1.183316e-04  8.826792e-05   \n",
       "std    ...  2.914535e-04  4.342999e-04  2.504480e-04  1.987508e-04   \n",
       "min    ...  1.999945e-07  3.522000e-08  4.288722e-08  4.606564e-08   \n",
       "25%    ...  5.343705e-05  1.422235e-05  1.135387e-05  1.351561e-05   \n",
       "50%    ...  1.539860e-04  4.832792e-05  3.004191e-05  3.498999e-05   \n",
       "75%    ...  2.842402e-04  1.951739e-04  8.691447e-05  7.285828e-05   \n",
       "max    ...  6.424147e-03  4.609045e-03  3.868459e-03  2.896981e-03   \n",
       "\n",
       "          PSD_O2_f7     PSD_F3_f7     PSD_C3_f7     PSD_T3_f7     PSD_O1_f7  \\\n",
       "count  1.256900e+04  1.256900e+04  1.256900e+04  1.256900e+04  1.256900e+04   \n",
       "mean   1.054856e-04  1.636815e-04  9.549801e-05  1.600020e-04  1.352673e-04   \n",
       "std    3.374096e-04  3.856515e-04  2.133908e-04  4.014707e-04  3.270955e-04   \n",
       "min    2.392012e-08  8.628437e-08  3.710131e-08  4.910864e-08  3.721586e-08   \n",
       "25%    1.139309e-05  1.409709e-05  1.118693e-05  1.554807e-05  1.188231e-05   \n",
       "50%    3.117250e-05  3.580749e-05  3.120121e-05  4.541531e-05  3.682110e-05   \n",
       "75%    6.686483e-05  1.074265e-04  7.518804e-05  1.061626e-04  8.855059e-05   \n",
       "max    4.815132e-03  4.759098e-03  2.972491e-03  4.737876e-03  4.155286e-03   \n",
       "\n",
       "          PSD_Cz_f7  \n",
       "count  1.256900e+04  \n",
       "mean   5.970503e-05  \n",
       "std    1.401175e-04  \n",
       "min    2.824243e-08  \n",
       "25%    8.736179e-06  \n",
       "50%    2.136704e-05  \n",
       "75%    4.698250e-05  \n",
       "max    2.978245e-03  \n",
       "\n",
       "[8 rows x 72 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12600\n",
      "12569\n"
     ]
    }
   ],
   "source": [
    "data_df = df.dropna()\n",
    "print(len(df.index))\n",
    "print(len(data_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "12595    2\n",
       "12596    2\n",
       "12597    2\n",
       "12598    2\n",
       "12599    2\n",
       "Name: grade, Length: 12569, dtype: category\n",
       "Categories (4, object): ['1', '2', '3', '4']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_df['grade']\n",
    "X = data_df[cols]\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6607000795544948"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC().fit(X_train, y_train)\n",
    "clf_svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8122513922036595"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "clf_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n",
      "c:\\Python37\\lib\\site-packages\\sklearn\\base.py:451: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7319013524264121"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf_nn = MLPClassifier(hidden_layer_sizes=(150,100,50),max_iter=500, early_stopping=True).fit(X_train, y_train)\n",
    "clf_nn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next:\n",
    "\n",
    "- Confusion matrix, precision-recall, and other evaluation metrics\n",
    "- Cross validation: https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "- More feature engineering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "different classifiers: https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
