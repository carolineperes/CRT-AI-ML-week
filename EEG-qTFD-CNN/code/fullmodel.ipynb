{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the grades (classes) for each file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_ID</th>\n",
       "      <th>baby_ID</th>\n",
       "      <th>epoch_number</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID01_epoch1</td>\n",
       "      <td>ID01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID01_epoch2</td>\n",
       "      <td>ID01</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID02_epoch1</td>\n",
       "      <td>ID02</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID02_epoch2</td>\n",
       "      <td>ID02</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID02_epoch3</td>\n",
       "      <td>ID02</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>ID52_epoch1</td>\n",
       "      <td>ID52</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>ID52_epoch2</td>\n",
       "      <td>ID52</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>ID52_epoch3</td>\n",
       "      <td>ID52</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>ID52_epoch4</td>\n",
       "      <td>ID52</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>ID53_epoch1</td>\n",
       "      <td>ID53</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_ID baby_ID  epoch_number  grade\n",
       "0    ID01_epoch1    ID01             1    NaN\n",
       "1    ID01_epoch2    ID01             2    NaN\n",
       "2    ID02_epoch1    ID02             1    1.0\n",
       "3    ID02_epoch2    ID02             2    2.0\n",
       "4    ID02_epoch3    ID02             3    1.0\n",
       "..           ...     ...           ...    ...\n",
       "164  ID52_epoch1    ID52             1    NaN\n",
       "165  ID52_epoch2    ID52             2    NaN\n",
       "166  ID52_epoch3    ID52             3    NaN\n",
       "167  ID52_epoch4    ID52             4    NaN\n",
       "168  ID53_epoch1    ID53             1    NaN\n",
       "\n",
       "[169 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_df = pd.read_csv(\"../data/eeg_grades.csv\")\n",
    "grades_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import the `.mat` files with preprocessed data (preprocessing done in MatLab, see `process_qtfd.m` script)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each `.mat` file contains variables:\n",
    "- `eeg_sig` : processed eeg signal before qtfd, with shape (t, channels, segments). \n",
    "\t- *t* is the number of points in a 5 min segment, downsampled to 64 Hz. \n",
    "\t- *channels* is the number of bipolar channels. \n",
    "\t- *segments* is the number of segments of 5 min from the original 1 H file (50% overlap).\n",
    "- `qtfd` is the output of the qTFD transform (`full_qtfd()` on MatLab created by J. O'Toole), in the shape (256, 128, 8, 23)\n",
    "- `qtfd_log` is the log of the absolute of `qtfd` (final preprocessing step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "file_ext = \".mat\"\n",
    "data_basepath = \"../data/MAT_format/\"\n",
    "data_files = list(grades_df['file_ID'])\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data file: dict_keys(['__header__', '__version__', '__globals__', 'eeg_sig', 'qtfd', 'qtfd_log'])\n",
      "eeg_sig shape: (19200, 8, 23)\n",
      "qtfd_log shape: (256, 128, 8, 23)\n"
     ]
    }
   ],
   "source": [
    "test = loadmat('../data/MAT_format/ID01_epoch1.mat')\n",
    "print('data file: ' + str(test.keys()))\n",
    "print('eeg_sig shape: ' + str(test['eeg_sig'].shape))\n",
    "print('qtfd_log shape: ' + str(test['qtfd_log'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`qtfd_log` is the input for the CNN. It is a (256, 128) matrix for each of the 8 channels divided into 23 segments of 5 min (50% overlap). We save that into `data_qtfd`, a dictionary with the filename as key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_qtfd = dict()\n",
    "for fname in data_files:\n",
    "\tdata_mat = loadmat(data_basepath + fname + '.mat')\n",
    "\tdata_qtfd[fname] = np.array(data_mat['qtfd_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'data_qtfd' (dict)\n"
     ]
    }
   ],
   "source": [
    "# store the qtfd data we just loaded\n",
    "%store data_qtfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload data_qtfd in case the notebook kernel is restarted\n",
    "%store -r data_qtfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 128, 8, 23)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'ID06_epoch1'\n",
    "data_qtfd[fname].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training and testing of the model, we drop the files without grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_grades_df = grades_df.dropna()\n",
    "train_test_grades_df = train_test_grades_df.set_index('file_ID')\n",
    "train_test_files = list(train_test_grades_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final preprocessing step: remove components 0-2 Hz and 30-32Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chop_f = True\n",
    "\n",
    "if chop_f:\n",
    "\tqtfd_shape = (256,112)\n",
    "else:\n",
    "\tqtfd_shape = list(data_qtfd.values())[1].shape[0:2]  #(256, 128)\n",
    "\n",
    "\n",
    "def get_qtfd(fname, ch, seg):\n",
    "\tqtfd = data_qtfd[fname]\n",
    "\tif chop_f:\n",
    "\t\treturn qtfd[:, 7:119, ch, seg]\n",
    "\telse:\n",
    "\t\treturn qtfd[:, :, ch, seg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape input train_test_x:  (19320, 256, 112)\n",
      "shape target train_test_y:  (19320, 1)\n"
     ]
    }
   ],
   "source": [
    "nsegm = list(data_qtfd.values())[1].shape[3]\n",
    "nch = list(data_qtfd.values())[1].shape[2]\n",
    "nfiles = len(train_test_grades_df.index)\n",
    "n_total_inputs = nsegm*nch*nfiles\n",
    "\n",
    "train_test_x = np.empty( (n_total_inputs, qtfd_shape[0], qtfd_shape[1]) )\n",
    "train_test_y = np.empty( (n_total_inputs, 1) )\n",
    "\n",
    "print('shape input train_test_x: ', train_test_x.shape)\n",
    "print('shape target train_test_y: ', train_test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nfiles):\n",
    "\tfname = train_test_files[i]\n",
    "\t# print(fname)\n",
    "\tfor j in range(nsegm):\n",
    "\t\tfor k in range(nch):\n",
    "\t\t\tn = i*(nsegm*nch) + j*nch + k;\n",
    "\t\t\t#print(n)\n",
    "\t\t\ttrain_test_x[n,:,:] = get_qtfd(fname, k, j)\n",
    "\t\t\ttrain_test_y[n] = train_test_grades_df['grade'].loc[fname]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `train_test_x` has a list of 256x128 (or 256x112 if `chop_f=True`) matrices that will be the inputs of the CNN, and `train_test_y` has the list of classes for each matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame for all data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Pandas DataFrame so we can control the Leave-One-Subject-Out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists to create the dataframe\n",
    "file_ID = []\n",
    "baby_ID = []\n",
    "epoch = []\n",
    "segment = []\n",
    "channel = []\n",
    "qtfd = []\n",
    "grade = []\n",
    "\n",
    "grades_df = grades_df.set_index('file_ID')\n",
    "filenames = list(grades_df.index)\n",
    "for i, fname in enumerate(filenames):\n",
    "\t# print(fname)\n",
    "\tfor j in range(nsegm):\n",
    "\t\tfor k in range(nch):\n",
    "\t\t\tn = i*(nsegm*nch) + j*nch + k;\n",
    "\t\t\t#print(n)\n",
    "\t\t\tfile_ID.append(fname)\n",
    "\t\t\tbaby_ID.append(grades_df['baby_ID'].loc[fname])\n",
    "\t\t\tepoch.append(grades_df['epoch_number'].loc[fname])\n",
    "\t\t\tsegment.append(j)\n",
    "\t\t\tchannel.append(k)\n",
    "\t\t\tqtfd.append(get_qtfd(fname, k, j))\n",
    "\t\t\tgrade.append(grades_df['grade'].loc[fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_ID</th>\n",
       "      <th>baby_ID</th>\n",
       "      <th>epoch</th>\n",
       "      <th>segment</th>\n",
       "      <th>channel</th>\n",
       "      <th>qTFD</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID01_epoch1</td>\n",
       "      <td>ID01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[6.6023696353706764, 6.15385990503455, 5.5655...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID01_epoch1</td>\n",
       "      <td>ID01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[5.956437627684241, 6.171991320782033, 6.3732...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID01_epoch1</td>\n",
       "      <td>ID01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[5.790945571769252, 5.8214202914188204, 5.785...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID01_epoch1</td>\n",
       "      <td>ID01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[[6.35190778713108, 6.305407904325214, 6.22342...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID01_epoch1</td>\n",
       "      <td>ID01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[[7.006041303088381, 6.906027779704137, 6.7721...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31091</th>\n",
       "      <td>ID53_epoch1</td>\n",
       "      <td>ID53</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>[[6.458609932430011, 6.213766185376376, 5.7423...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31092</th>\n",
       "      <td>ID53_epoch1</td>\n",
       "      <td>ID53</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>[[10.358890774999143, 10.023876847405162, 9.60...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31093</th>\n",
       "      <td>ID53_epoch1</td>\n",
       "      <td>ID53</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>[[7.435327945244904, 6.913063945796877, 6.0541...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31094</th>\n",
       "      <td>ID53_epoch1</td>\n",
       "      <td>ID53</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>[[6.10206505040248, 6.028219188968934, 5.74461...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31095</th>\n",
       "      <td>ID53_epoch1</td>\n",
       "      <td>ID53</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>[[6.2018062060017165, 5.811695169484539, 5.524...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31096 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_ID baby_ID  epoch  segment  channel  \\\n",
       "0      ID01_epoch1    ID01      1        0        0   \n",
       "1      ID01_epoch1    ID01      1        0        1   \n",
       "2      ID01_epoch1    ID01      1        0        2   \n",
       "3      ID01_epoch1    ID01      1        0        3   \n",
       "4      ID01_epoch1    ID01      1        0        4   \n",
       "...            ...     ...    ...      ...      ...   \n",
       "31091  ID53_epoch1    ID53      1       22        3   \n",
       "31092  ID53_epoch1    ID53      1       22        4   \n",
       "31093  ID53_epoch1    ID53      1       22        5   \n",
       "31094  ID53_epoch1    ID53      1       22        6   \n",
       "31095  ID53_epoch1    ID53      1       22        7   \n",
       "\n",
       "                                                    qTFD  grade  \n",
       "0      [[6.6023696353706764, 6.15385990503455, 5.5655...    NaN  \n",
       "1      [[5.956437627684241, 6.171991320782033, 6.3732...    NaN  \n",
       "2      [[5.790945571769252, 5.8214202914188204, 5.785...    NaN  \n",
       "3      [[6.35190778713108, 6.305407904325214, 6.22342...    NaN  \n",
       "4      [[7.006041303088381, 6.906027779704137, 6.7721...    NaN  \n",
       "...                                                  ...    ...  \n",
       "31091  [[6.458609932430011, 6.213766185376376, 5.7423...    NaN  \n",
       "31092  [[10.358890774999143, 10.023876847405162, 9.60...    NaN  \n",
       "31093  [[7.435327945244904, 6.913063945796877, 6.0541...    NaN  \n",
       "31094  [[6.10206505040248, 6.028219188968934, 5.74461...    NaN  \n",
       "31095  [[6.2018062060017165, 5.811695169484539, 5.524...    NaN  \n",
       "\n",
       "[31096 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = {'file_ID': file_ID, 'baby_ID': baby_ID, 'epoch': epoch, 'segment': segment, 'channel': channel, 'qTFD': qtfd, 'grade': grade}\n",
    "data = pd.DataFrame(data_dict)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'data' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_ID</th>\n",
       "      <th>baby_ID</th>\n",
       "      <th>epoch</th>\n",
       "      <th>segment</th>\n",
       "      <th>channel</th>\n",
       "      <th>qTFD</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>ID02_epoch1</td>\n",
       "      <td>ID02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[6.9388474487104705, 8.04235544553957, 7.0435...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>ID02_epoch1</td>\n",
       "      <td>ID02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[5.633287187614542, 5.224858890958373, 4.3496...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>ID02_epoch1</td>\n",
       "      <td>ID02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[[7.637610076410876, 8.371093580089752, 7.2013...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>ID02_epoch1</td>\n",
       "      <td>ID02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[[7.1952406368287205, 7.664078726379879, 6.845...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>ID02_epoch1</td>\n",
       "      <td>ID02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[[7.03630080417184, 7.634677625886598, 7.02603...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30171</th>\n",
       "      <td>ID51_epoch4</td>\n",
       "      <td>ID51</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>[[2.314323884614313, 3.001018120724679, 2.2154...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30172</th>\n",
       "      <td>ID51_epoch4</td>\n",
       "      <td>ID51</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>[[3.4156377448221775, 3.434901567824473, 2.618...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30173</th>\n",
       "      <td>ID51_epoch4</td>\n",
       "      <td>ID51</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>[[4.033218579672476, 3.7532375324865472, 2.902...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30174</th>\n",
       "      <td>ID51_epoch4</td>\n",
       "      <td>ID51</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>[[4.3772613640678, 3.7530439324956113, 3.01815...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30175</th>\n",
       "      <td>ID51_epoch4</td>\n",
       "      <td>ID51</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>[[3.5621446384464575, 3.3669721529818997, 1.71...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           file_ID baby_ID  epoch  segment  channel  \\\n",
       "368    ID02_epoch1    ID02      1        0        0   \n",
       "369    ID02_epoch1    ID02      1        0        1   \n",
       "370    ID02_epoch1    ID02      1        0        2   \n",
       "371    ID02_epoch1    ID02      1        0        3   \n",
       "372    ID02_epoch1    ID02      1        0        4   \n",
       "...            ...     ...    ...      ...      ...   \n",
       "30171  ID51_epoch4    ID51      4       22        3   \n",
       "30172  ID51_epoch4    ID51      4       22        4   \n",
       "30173  ID51_epoch4    ID51      4       22        5   \n",
       "30174  ID51_epoch4    ID51      4       22        6   \n",
       "30175  ID51_epoch4    ID51      4       22        7   \n",
       "\n",
       "                                                    qTFD  grade  \n",
       "368    [[6.9388474487104705, 8.04235544553957, 7.0435...    1.0  \n",
       "369    [[5.633287187614542, 5.224858890958373, 4.3496...    1.0  \n",
       "370    [[7.637610076410876, 8.371093580089752, 7.2013...    1.0  \n",
       "371    [[7.1952406368287205, 7.664078726379879, 6.845...    1.0  \n",
       "372    [[7.03630080417184, 7.634677625886598, 7.02603...    1.0  \n",
       "...                                                  ...    ...  \n",
       "30171  [[2.314323884614313, 3.001018120724679, 2.2154...    2.0  \n",
       "30172  [[3.4156377448221775, 3.434901567824473, 2.618...    2.0  \n",
       "30173  [[4.033218579672476, 3.7532375324865472, 2.902...    2.0  \n",
       "30174  [[4.3772613640678, 3.7530439324956113, 3.01815...    2.0  \n",
       "30175  [[3.5621446384464575, 3.3669721529818997, 1.71...    2.0  \n",
       "\n",
       "[19320 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_test = data.dropna().copy()\n",
    "data_train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(from `Infant.ipynb` by Oisin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CNN layers and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D, MaxPooling2D, AveragePooling2D, Dropout,GlobalAveragePooling2D, MaxPooling1D \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convnet():\n",
    "    # layers as specified in the paper\n",
    "    input_shape = tf.keras.Input(shape=(256, 112, 1))\n",
    "\n",
    "    tower_1 = Conv2D(10, (8, 1), padding='same', activation='relu')(input_shape)\n",
    "    tower_1 = MaxPooling2D((4, 4), strides=(2, 2), padding='same')(tower_1)\n",
    "\n",
    "    tower_2 = Conv2D(10, (1, 8), padding='same', activation='relu')(input_shape)\n",
    "    tower_2 = MaxPooling2D((4, 4), strides=(2, 2), padding='same')(tower_2)\n",
    "\n",
    "    tower_3 = Conv2D(10, (8, 8), padding='same', activation='relu')(input_shape)\n",
    "    tower_3 = MaxPooling2D((4, 4), strides=(2, 2), padding='same')(tower_3)\n",
    "\n",
    "    merged = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=3)\n",
    "\n",
    "    layer1 = Conv2D(60, (4,4), padding='same', \n",
    "                    activation ='relu',strides =(2,2))(merged)\n",
    "    \n",
    "    layer2a = MaxPooling2D((2,2), padding ='same', strides =(2,2))(layer1)\n",
    "    layer2b = BatchNormalization()(layer2a)\n",
    "    layer3 = Conv2D(60, (2,2), padding='same' )(layer2b)\n",
    "\n",
    "    layer4 = MaxPooling2D( (2,2), padding='same', strides =(2,2))(layer3)\n",
    "    layer5 = GlobalAveragePooling2D()(layer4)\n",
    "\n",
    "    out = Dense(60, activation='relu')(layer5)\n",
    "    out = Dense(4, activation='softmax')(out)\n",
    "\n",
    "    model = tf.keras.Model(input_shape, out)\n",
    "    #plot_model(model, to_file=img_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 112, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 112, 10  90          ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 112, 10  90          ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 256, 112, 10  650         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 56, 10)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 128, 56, 10)  0          ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 128, 56, 10)  0          ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128, 56, 30)  0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'max_pooling2d_1[0][0]',        \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 28, 60)   28860       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 32, 14, 60)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 14, 60)  240         ['max_pooling2d_3[0][0]']        \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 14, 60)   14460       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 16, 7, 60)   0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 60)          0           ['max_pooling2d_4[0][0]']        \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 60)           3660        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4)            244         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 48,294\n",
      "Trainable params: 48,174\n",
      "Non-trainable params: 120\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 12:51:17.965702: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-26 12:51:17.966294: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = create_convnet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the learning rate step\n",
    "def scheduler(epoch, lr):\n",
    "  n =np.floor((epoch-1)/5)\n",
    "  return lr*(0.8)**n\n",
    "opt = tf.keras.optimizers.SGD(momentum =0.9, nesterov =True)\n",
    "callback_lr = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(opt,loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(x=x, y=y, epochs=30, batch_size=128, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpredict(x):\n",
    "  return model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate training and test data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use LOSO (leave-one-subject-out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368      ID02\n",
       "369      ID02\n",
       "370      ID02\n",
       "371      ID02\n",
       "372      ID02\n",
       "         ... \n",
       "30171    ID51\n",
       "30172    ID51\n",
       "30173    ID51\n",
       "30174    ID51\n",
       "30175    ID51\n",
       "Name: baby_ID, Length: 19320, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects = data_train_test['baby_ID']\n",
    "subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each subject in subjects\n",
    "# drop from dataframe the rows corresponding to that subject ID\n",
    "# train = df[!subjectID]\n",
    "# test = df[subjectID]\n",
    "# fit model to train data\n",
    "# get evaluation metricts by predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_train_test['grade']\n",
    "X = data_train_test['qTFD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "logo = LeaveOneGroupOut()\n",
    "logo.get_n_splits(X,y,subjects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-26 12:52:07.694613: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-08-26 12:52:07.955889: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# LOSO Cross Validation\n",
    "fold_no = 1\n",
    "for train_index, test_index in logo.split(X,y,subjects):\n",
    "\t# separate train and test based on group\n",
    "\tX_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "\ty_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "\t# convert X to ndarrays of (n, 256, 112) shape\n",
    "\t# and y to (n, 1)\n",
    "\tX_train = np.reshape(list(X_train), (len(X_train), 256, 112))\n",
    "\tX_test = np.reshape(list(X_test), (len(X_test), 256, 112))\n",
    "\t# y_train = np.reshape(list(y_train), (len(y_train), 1)).astype(np.int32)\n",
    "\t# y_train = list(y_train - 1)\n",
    "\t# y_test = list(y_test)\n",
    "\ty_train = tf.keras.utils.to_categorical(y_train - 1, num_classes=4)\n",
    "\ty_test = tf.keras.utils.to_categorical(y_test - 1, num_classes=4)\n",
    "\n",
    "\t# create model architecture\n",
    "\tmodel = create_convnet()\n",
    "\topt = tf.keras.optimizers.SGD(momentum =0.9, nesterov =True)\n",
    "\tcallback_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "\t# compile model\n",
    "\tmodel.compile(opt,loss='categorical_crossentropy')\n",
    "\n",
    "\t# print\n",
    "\tprint('------------------------------------------------------------------------') \n",
    "\tprint(f'Training for fold {fold_no} ...')\n",
    "\n",
    "\t# fit model\n",
    "\thistory = model.fit(x=X_test, y=y_test, \n",
    "\t\tepochs=1, batch_size=4, callbacks=[callback_lr])\n",
    "\n",
    "\t# get metrics\n",
    "\tscores = model.evaluate(x=X_test, y=y_test, verbose=0)\n",
    "\tprint(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "\n",
    "\tfold_no += 1\n",
    "\tbreak\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "725237425e08672101b1a59e5e8e9973356242210d461e01663e4da929b4f5d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
